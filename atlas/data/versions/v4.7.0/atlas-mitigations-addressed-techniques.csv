source ID,source name,source ref,source type,mapping type,target ID,target name,target ref,target type,mapping description,STIX ID,created,last modified
AML.M0023,AI Bill of Materials,course-of-action--1f63b56d-034f-477d-ab49-399c1aa1a22a,mitigation,mitigates,AML.T0020,Poison Training Data,attack-pattern--0ec538ca-589b-4e42-bcaa-06097a0d679f,technique,An AI BOM can help users identify untrustworthy model artifacts.,relationship--505db5cc-8d11-4811-8e90-006612c440d0,01 October 2024,01 October 2024
AML.M0023,AI Bill of Materials,course-of-action--1f63b56d-034f-477d-ab49-399c1aa1a22a,mitigation,mitigates,AML.T0019,Publish Poisoned Datasets,attack-pattern--f4fc2abd-71a4-401a-a742-18fc5aeb4bc3,technique,An AI BOM can help users identify untrustworthy model artifacts.,relationship--9f6e8c64-bd4d-42cc-9a5e-9fc13646c437,01 October 2024,01 October 2024
AML.M0023,AI Bill of Materials,course-of-action--1f63b56d-034f-477d-ab49-399c1aa1a22a,mitigation,mitigates,AML.T0058,Publish Poisoned Models,attack-pattern--e3b9d41a-d2f9-4825-942f-1c4a30b4d2f9,technique,An AI BOM can help users identify untrustworthy model artifacts.,relationship--f49686fb-e313-4b3a-8217-e389b6553316,01 October 2024,01 October 2024
AML.M0023,AI Bill of Materials,course-of-action--1f63b56d-034f-477d-ab49-399c1aa1a22a,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,An AI BOM can help users identify untrustworthy model artifacts.,relationship--49a027cf-833c-4f17-9b4c-0fdd04274e48,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0040,AI Model Inference API Access,attack-pattern--90a420d4-3f03-4800-86c0-223c4376804a,technique,Telemetry logging can help audit API usage of the model.,relationship--6dbfe2fe-3636-4656-aaa3-1f6f985f751a,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0051.000,Direct,attack-pattern--d911e8cb-0601-42f1-90de-7ce0b21cd578,technique,Telemetry logging can help identify if unsafe prompts have been submitted to the LLM.,relationship--e2ec223a-c3ca-4bf7-a167-f13e6645aae6,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0024,Exfiltration via ML Inference API,attack-pattern--b07d147f-51c8-4eb6-9a05-09c86762a9c1,technique,Telemetry logging can help identify if sensitive data has been exfiltrated.,relationship--0189dc45-3210-491f-8099-11fa3447740b,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0024.002,Extract ML Model,attack-pattern--f78e0ac3-6d72-42ed-b20a-e10d8c752cf6,technique,Telemetry logging can help identify if sensitive data has been exfiltrated.,relationship--34b01208-4b99-4099-bf6a-61f172bcf048,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0051.001,Indirect,attack-pattern--a4a55526-2f1f-403b-9691-609e46381e17,technique,Telemetry logging can help identify if unsafe prompts have been submitted to the LLM.,relationship--767ad4ac-4061-4dc7-a179-4f983c9e3582,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0024.000,Infer Training Data Membership,attack-pattern--86b5f486-afb8-4aa9-991f-0e24d5737f0c,technique,Telemetry logging can help identify if sensitive data has been exfiltrated.,relationship--58bb8cef-12fc-4b51-ba19-308805a65015,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0024.001,Invert ML Model,attack-pattern--e19c6f8a-f1e2-46cc-9387-03a3092f01ed,technique,Telemetry logging can help identify if sensitive data has been exfiltrated.,relationship--61bf5a36-058b-4c1f-9717-73cd06ee702d,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0051,LLM Prompt Injection,attack-pattern--19cd2d12-66ff-487c-a05c-e058b027efc9,technique,Telemetry logging can help identify if unsafe prompts have been submitted to the LLM.,relationship--7350b9b9-0754-4b6a-a1b6-961abb7b65cd,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0047,ML-Enabled Product or Service,attack-pattern--b5626410-b33d-4487-9c0f-2b7d844b8e95,technique,Telemetry logging can help identify if sensitive model information has been sent to an attacker.,relationship--d221f109-20ae-4067-8dee-982f89fc01d6,01 October 2024,01 October 2024
AML.M0024,AI Telemetry Logging,course-of-action--fa5108b2-3dc8-42dc-93a3-902f1bf74521,mitigation,mitigates,AML.T0005.001,Train Proxy via Replication,attack-pattern--a3660a2d-f6e5-4f1b-9618-332cceb389c8,technique,Telemetry logging can help identify if a proxy training dataset has been exfiltrated.,relationship--f1398de1-0015-438b-9771-fc0945cdd2c8,01 October 2024,01 October 2024
AML.M0015,Adversarial Input Detection,course-of-action--0ed2ef71-cdc9-4eef-8432-1c3dadbdda20,mitigation,mitigates,AML.T0043.001,Black-Box Optimization,attack-pattern--c4e52005-7416-45c4-9feb-8cd5fd34f70a,technique,"Monitor queries and query patterns to the target model, block access if suspicious queries are detected.
",relationship--51024f40-3973-45e7-9e4b-0d44b96494a6,12 April 2023,12 October 2023
AML.M0015,Adversarial Input Detection,course-of-action--0ed2ef71-cdc9-4eef-8432-1c3dadbdda20,mitigation,mitigates,AML.T0029,Denial of ML Service,attack-pattern--8f644f37-e2e6-468e-b720-f395b8c27fbc,technique,"Assess queries before inference call or enforce timeout policy for queries which consume excessive resources.
",relationship--5b01cc8b-0726-40cd-9236-64a0861b9ced,12 April 2023,12 October 2023
AML.M0015,Adversarial Input Detection,course-of-action--0ed2ef71-cdc9-4eef-8432-1c3dadbdda20,mitigation,mitigates,AML.T0031,Erode ML Model Integrity,attack-pattern--8735735d-c09d-4298-8e64-9a2b6168a74c,technique,"Incorporate adversarial input detection into the pipeline before inputs reach the model.
",relationship--6779bab3-aa88-40cd-8da3-43dbf5775f94,12 April 2023,12 October 2023
AML.M0015,Adversarial Input Detection,course-of-action--0ed2ef71-cdc9-4eef-8432-1c3dadbdda20,mitigation,mitigates,AML.T0015,Evade ML Model,attack-pattern--071df654-813a-4708-85dc-f715f785d37f,technique,"Prevent an attacker from introducing adversarial data into the system.
",relationship--7da0d729-7305-4768-a378-c67e085b7266,12 April 2023,12 October 2023
AML.M0013,Code Signing,course-of-action--88073b07-2fe9-41cb-8e76-6e244fbabc74,mitigation,mitigates,AML.T0010.001,ML Software,attack-pattern--d8292a1c-21e7-4b45-b110-0e05feb30a9a,technique,"Enforce properly signed drivers and ML software frameworks.
",relationship--b3b1d2a9-e13d-44dc-b089-3796550a80ce,12 April 2023,12 October 2023
AML.M0013,Code Signing,course-of-action--88073b07-2fe9-41cb-8e76-6e244fbabc74,mitigation,mitigates,AML.T0010.003,Model,attack-pattern--452b8fdf-8679-4013-bb38-4d16f65430bc,technique,"Enforce properly signed model files.
",relationship--ce00abe6-d133-404d-b3a8-ff7469897397,12 April 2023,12 October 2023
AML.M0013,Code Signing,course-of-action--88073b07-2fe9-41cb-8e76-6e244fbabc74,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,"Prevent execution of ML artifacts that are not properly signed.
",relationship--5a263177-67a7-4d06-9939-85c51711c3be,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0010.002,Data,attack-pattern--8d644240-ad99-4410-a7f8-3ef8f53a463e,technique,"Access controls can prevent tampering with ML artifacts and prevent unauthorized copying.
",relationship--1bf1eb9c-25ea-4114-b044-5ad99526ce35,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0025,Exfiltration via Cyber Means,attack-pattern--2680aa95-5620-4677-9c62-b0c3d15d9450,technique,"Access controls can prevent exfiltration.
",relationship--59cd016a-ff20-44d6-8997-b98c4c9f23e3,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0018.001,Inject Payload,attack-pattern--a50f02df-1130-4945-94bb-7857952da585,technique,"Access controls can prevent tampering with ML artifacts and prevent unauthorized copying.
",relationship--07a09112-35b6-4acd-ab4c-b1b40283b67d,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0048.004,ML Intellectual Property Theft,attack-pattern--d1f013a8-11f3-4560-831c-8ed5e39247c9,technique,"Access controls can prevent theft of intellectual property.
",relationship--3d041f61-1f41-4d92-a871-0204d00b88d5,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0010.003,Model,attack-pattern--452b8fdf-8679-4013-bb38-4d16f65430bc,technique,"Access controls can prevent tampering with ML artifacts and prevent unauthorized copying.
",relationship--2077df23-3928-4527-ba1c-3ff12ec506d0,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0018.000,Poison ML Model,attack-pattern--e0eb2b64-aebd-4412-80f3-b71d7805a65f,technique,"Access controls can prevent tampering with ML artifacts and prevent unauthorized copying.
",relationship--b1eced87-94e4-41f1-8b3c-84f6fe1e6b1f,12 April 2023,12 October 2023
AML.M0005,Control Access to ML Models and Data at Rest,course-of-action--0025dadf-7900-497f-aa03-39f0e319f20e,mitigation,mitigates,AML.T0020,Poison Training Data,attack-pattern--0ec538ca-589b-4e42-bcaa-06097a0d679f,technique,"Access controls can prevent tampering with ML artifacts and prevent unauthorized copying.
",relationship--1560458c-50af-460f-9b93-ec048ae440a9,12 April 2023,12 October 2023
AML.M0019,Control Access to ML Models and Data in Production,course-of-action--7b00dd51-f719-433d-afd6-3d386f64386d,mitigation,mitigates,AML.T0040,AI Model Inference API Access,attack-pattern--90a420d4-3f03-4800-86c0-223c4376804a,technique,"Adversaries can use unrestricted API access to gain information about a production system, stage attacks, and introduce malicious data to the system.
",relationship--1e7c2309-9d9d-47f9-9a01-afdacbbff726,12 January 2024,12 January 2024
AML.M0019,Control Access to ML Models and Data in Production,course-of-action--7b00dd51-f719-433d-afd6-3d386f64386d,mitigation,mitigates,AML.T0024,Exfiltration via ML Inference API,attack-pattern--b07d147f-51c8-4eb6-9a05-09c86762a9c1,technique,"Adversaries can use unrestricted API access to build a proxy training dataset and reveal private information.
",relationship--2085409e-80d1-4208-9a33-10f29c0674cf,12 January 2024,12 January 2024
AML.M0012,Encrypt Sensitive Information,course-of-action--aad92d43-774b-4612-8437-8d6c7ee7e4af,mitigation,mitigates,AML.T0007,Discover ML Artifacts,attack-pattern--6a88dccb-fb37-4f11-a5ad-42908aaee1d0,technique,"Protect machine learning artifacts from adversaries who gather private information to target and improve attacks.
",relationship--8ee2f4d3-7ca9-429b-98a6-9846e7bce04a,12 April 2023,12 October 2023
AML.M0012,Encrypt Sensitive Information,course-of-action--aad92d43-774b-4612-8437-8d6c7ee7e4af,mitigation,mitigates,AML.T0035,ML Artifact Collection,attack-pattern--e2ebc190-9ff6-496e-afeb-ac868df2361e,technique,"Protect machine learning artifacts with encryption.
",relationship--b3f929e4-e875-4c18-8534-804190dc61fc,12 April 2023,12 October 2023
AML.M0012,Encrypt Sensitive Information,course-of-action--aad92d43-774b-4612-8437-8d6c7ee7e4af,mitigation,mitigates,AML.T0048.004,ML Intellectual Property Theft,attack-pattern--d1f013a8-11f3-4560-831c-8ed5e39247c9,technique,"Protect machine learning artifacts with encryption.
",relationship--4f3f445c-d094-456c-9a12-7ee310f97bd7,12 April 2023,12 October 2023
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0057,LLM Data Leakage,attack-pattern--45d378aa-20ae-401d-bf61-7f00104eeaca,technique,Guardrails can detect sensitive data and PII in model outputs.,relationship--ed1773d0-00a6-4df5-9b28-8404a2c18694,01 October 2024,01 October 2024
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0054,LLM Jailbreak,attack-pattern--172427e3-9ecc-49a3-b628-96b824cc4131,technique,Guardrails can prevent harmful inputs that can lead to a jailbreak.,relationship--10ddba73-06cf-4842-9d8a-619e32320d58,01 October 2024,01 October 2024
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0056,LLM Meta Prompt Extraction,attack-pattern--e98acce8-ed69-4ebe-845b-1bcb662836ba,technique,Guardrails can prevent harmful inputs that can lead to meta prompt extraction.,relationship--0f347c93-ea71-48b0-a2c2-412eb839d9aa,01 October 2024,01 October 2024
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0053,LLM Plugin Compromise,attack-pattern--adbb0dd5-ff66-4b2f-869f-bfb3fdb45fc8,technique,"Guardrails can prevent harmful inputs that can lead to plugin compromise, and they can detect PII in model outputs.",relationship--e6e258c3-5df6-4a53-8cf2-d49b66c3c168,01 October 2024,01 October 2024
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0051,LLM Prompt Injection,attack-pattern--19cd2d12-66ff-487c-a05c-e058b027efc9,technique,Guardrails can prevent harmful inputs that can lead to prompt injection.,relationship--4c2f0582-0c11-42c1-9f3c-57c3ae6678f5,01 October 2024,01 October 2024
AML.M0020,Generative AI Guardrails,course-of-action--b8511570-3320-4733-a0e1-134e376e7530,mitigation,mitigates,AML.T0010,ML Supply Chain Compromise,attack-pattern--d2cf31e0-a550-4fe0-8fdb-8941b3ac00d9,technique,Guardrails can detect harmful code in model outputs.,relationship--7fe1328a-4daf-4784-84af-00de83163fbe,01 October 2024,01 October 2024
AML.M0021,Generative AI Guidelines,course-of-action--d55bd0c8-2db0-400b-9097-c7cec00e2b91,mitigation,mitigates,AML.T0057,LLM Data Leakage,attack-pattern--45d378aa-20ae-401d-bf61-7f00104eeaca,technique,Model guidelines can instruct the model to refuse a response to unsafe inputs.,relationship--7511dfe2-5d1e-44e3-8cf1-cf1791affc6c,01 October 2024,01 October 2024
AML.M0021,Generative AI Guidelines,course-of-action--d55bd0c8-2db0-400b-9097-c7cec00e2b91,mitigation,mitigates,AML.T0054,LLM Jailbreak,attack-pattern--172427e3-9ecc-49a3-b628-96b824cc4131,technique,Model guidelines can instruct the model to refuse a response to unsafe inputs.,relationship--696185ad-91d8-478a-9810-41f6ff4b34ac,01 October 2024,01 October 2024
AML.M0021,Generative AI Guidelines,course-of-action--d55bd0c8-2db0-400b-9097-c7cec00e2b91,mitigation,mitigates,AML.T0056,LLM Meta Prompt Extraction,attack-pattern--e98acce8-ed69-4ebe-845b-1bcb662836ba,technique,Model guidelines can instruct the model to refuse a response to unsafe inputs.,relationship--80c30f25-c88c-4697-892a-ec032eec2a76,01 October 2024,01 October 2024
AML.M0021,Generative AI Guidelines,course-of-action--d55bd0c8-2db0-400b-9097-c7cec00e2b91,mitigation,mitigates,AML.T0053,LLM Plugin Compromise,attack-pattern--adbb0dd5-ff66-4b2f-869f-bfb3fdb45fc8,technique,Model guidelines can instruct the model to refuse a response to unsafe inputs.,relationship--6bf89225-c0c3-4abd-84cd-07d19a46cc88,01 October 2024,01 October 2024
AML.M0021,Generative AI Guidelines,course-of-action--d55bd0c8-2db0-400b-9097-c7cec00e2b91,mitigation,mitigates,AML.T0051,LLM Prompt Injection,attack-pattern--19cd2d12-66ff-487c-a05c-e058b027efc9,technique,Model guidelines can instruct the model to refuse a response to unsafe inputs.,relationship--87a2b66d-386a-4a41-97d7-cef879dc9dbc,01 October 2024,01 October 2024
AML.M0022,Generative AI Model Alignment,course-of-action--1fca595d-b140-4ce0-8fd8-c4c6bee87540,mitigation,mitigates,AML.T0057,LLM Data Leakage,attack-pattern--45d378aa-20ae-401d-bf61-7f00104eeaca,technique,Model alignment can improve the parametric safety of a model by guiding it away from unsafe prompts and responses.,relationship--df267ca5-9e7f-48f9-ae49-c00d7c2f03eb,01 October 2024,01 October 2024
AML.M0022,Generative AI Model Alignment,course-of-action--1fca595d-b140-4ce0-8fd8-c4c6bee87540,mitigation,mitigates,AML.T0054,LLM Jailbreak,attack-pattern--172427e3-9ecc-49a3-b628-96b824cc4131,technique,Model alignment can improve the parametric safety of a model by guiding it away from unsafe prompts and responses.,relationship--af332762-577c-4785-8ed3-a4cd5e76b016,01 October 2024,01 October 2024
AML.M0022,Generative AI Model Alignment,course-of-action--1fca595d-b140-4ce0-8fd8-c4c6bee87540,mitigation,mitigates,AML.T0056,LLM Meta Prompt Extraction,attack-pattern--e98acce8-ed69-4ebe-845b-1bcb662836ba,technique,Model alignment can improve the parametric safety of a model by guiding it away from unsafe prompts and responses.,relationship--c685aac1-12c7-4b33-b57d-63d39620cf37,01 October 2024,01 October 2024
AML.M0022,Generative AI Model Alignment,course-of-action--1fca595d-b140-4ce0-8fd8-c4c6bee87540,mitigation,mitigates,AML.T0053,LLM Plugin Compromise,attack-pattern--adbb0dd5-ff66-4b2f-869f-bfb3fdb45fc8,technique,Model alignment can improve the parametric safety of a model by guiding it away from unsafe prompts and responses.,relationship--19c6714e-d0fb-44b2-974c-c3d9d5dda4a7,01 October 2024,01 October 2024
AML.M0022,Generative AI Model Alignment,course-of-action--1fca595d-b140-4ce0-8fd8-c4c6bee87540,mitigation,mitigates,AML.T0051,LLM Prompt Injection,attack-pattern--19cd2d12-66ff-487c-a05c-e058b027efc9,technique,Model alignment can improve the parametric safety of a model by guiding it away from unsafe prompts and responses.,relationship--ef7d221b-4628-49c8-9f02-78f3bc74ec43,01 October 2024,01 October 2024
AML.M0010,Input Restoration,course-of-action--73a34f24-1ad1-4421-b9c8-c2cbd13e6f47,mitigation,mitigates,AML.T0043.001,Black-Box Optimization,attack-pattern--c4e52005-7416-45c4-9feb-8cd5fd34f70a,technique,"Input restoration adds an extra layer of unknowns and randomness when an adversary evaluates the input-output relationship.
",relationship--87ec7587-d0ba-4414-944e-19926ae67d54,12 April 2023,12 October 2023
AML.M0010,Input Restoration,course-of-action--73a34f24-1ad1-4421-b9c8-c2cbd13e6f47,mitigation,mitigates,AML.T0031,Erode ML Model Integrity,attack-pattern--8735735d-c09d-4298-8e64-9a2b6168a74c,technique,"Preprocessing model inputs can prevent malicious data from going through the machine learning pipeline.
",relationship--8724c1c4-9d16-406e-bdbe-f043878fba96,12 April 2023,12 October 2023
AML.M0010,Input Restoration,course-of-action--73a34f24-1ad1-4421-b9c8-c2cbd13e6f47,mitigation,mitigates,AML.T0015,Evade ML Model,attack-pattern--071df654-813a-4708-85dc-f715f785d37f,technique,"Preprocessing model inputs can prevent malicious data from going through the machine learning pipeline.
",relationship--84daf1fa-1912-489e-ba02-03000ba1dfb6,12 April 2023,12 October 2023
AML.M0001,Limit Model Artifact Release,course-of-action--79c75215-ada9-4c22-bfed-7d13fb6e966e,mitigation,mitigates,AML.T0002.000,Datasets,attack-pattern--a3baff3d-7228-4ab7-ae00-ffe150e7ef8a,technique,"Limiting the release of datasets can reduce an adversary's ability to target production models trained on the same or similar data.
",relationship--a7ce7eed-1966-46c9-b1f5-698b130b14ae,12 April 2023,12 October 2023
AML.M0001,Limit Model Artifact Release,course-of-action--79c75215-ada9-4c22-bfed-7d13fb6e966e,mitigation,mitigates,AML.T0002.001,Models,attack-pattern--c086784e-1494-4f75-a4a0-d3ad054b9428,technique,"Limiting the release of model architectures and checkpoints can reduce an adversary's ability to target those models.
",relationship--ded2770e-ec93-43d6-a402-17b719f06f64,12 April 2023,12 October 2023
AML.M0001,Limit Model Artifact Release,course-of-action--79c75215-ada9-4c22-bfed-7d13fb6e966e,mitigation,mitigates,AML.T0020,Poison Training Data,attack-pattern--0ec538ca-589b-4e42-bcaa-06097a0d679f,technique,"Published datasets can be a target for poisoning attacks.
",relationship--860a4243-92cc-455f-bc92-0a3f380f5cf8,12 April 2023,12 October 2023
AML.M0000,Limit Public Release of Information,course-of-action--40076545-e797-4508-a294-943096a12111,mitigation,mitigates,AML.T0002,Acquire Public ML Artifacts,attack-pattern--aa17fe8d-62f8-4c4c-b7a2-6858c82dd84b,technique,"Limit the release of sensitive information in the metadata of deployed systems and publicly available applications.
",relationship--fa2e9798-70d3-47bc-8d02-0adce4b8f4a9,12 April 2023,01 October 2024
AML.M0000,Limit Public Release of Information,course-of-action--40076545-e797-4508-a294-943096a12111,mitigation,mitigates,AML.T0004,Search Application Repositories,attack-pattern--8c26f51a-c403-4c4d-852a-a1c56fe9e7cd,technique,"Limit the release of sensitive information in the metadata of deployed systems and publicly available applications.
",relationship--d30ca2d6-bb30-4aa5-adeb-050a01bbbec1,12 April 2023,01 October 2024
AML.M0000,Limit Public Release of Information,course-of-action--40076545-e797-4508-a294-943096a12111,mitigation,mitigates,AML.T0003,Search Victim-Owned Websites,attack-pattern--b23cda85-3457-406d-b043-24d2cf9e6fcf,technique,"Restrict release of technical information on ML-enabled products and organizational information on the teams supporting ML-enabled products.
",relationship--e87ad122-14fe-4c8f-9fa4-19c8ef795c7c,12 April 2023,01 October 2024
AML.M0000,Limit Public Release of Information,course-of-action--40076545-e797-4508-a294-943096a12111,mitigation,mitigates,AML.T0000,Search for Victim's Publicly Available Research Materials,attack-pattern--65d21e6b-7abe-4623-8f5c-88011cb362cb,technique,"Limit the connection between publicly disclosed approaches and the data, models, and algorithms used in production.
",relationship--460fe1f6-b88d-415d-8433-ef4ccb40afd6,12 April 2023,01 October 2024
AML.M0025,Maintain AI Dataset Provenance,course-of-action--005a5427-4b1e-41c2-a7aa-eda9ae9a9815,mitigation,mitigates,AML.T0010.002,Data,attack-pattern--8d644240-ad99-4410-a7f8-3ef8f53a463e,technique,Dataset provenance can protect against supply chain compromise of data.,relationship--0889f025-d000-4362-8f7e-1672a0c5804c,01 October 2024,01 October 2024
AML.M0025,Maintain AI Dataset Provenance,course-of-action--005a5427-4b1e-41c2-a7aa-eda9ae9a9815,mitigation,mitigates,AML.T0018.000,Poison ML Model,attack-pattern--e0eb2b64-aebd-4412-80f3-b71d7805a65f,technique,Dataset provenance can protect against poisoning of models.,relationship--6f10f315-4dbf-48b1-a207-8765c5b76f20,01 October 2024,01 October 2024
AML.M0025,Maintain AI Dataset Provenance,course-of-action--005a5427-4b1e-41c2-a7aa-eda9ae9a9815,mitigation,mitigates,AML.T0020,Poison Training Data,attack-pattern--0ec538ca-589b-4e42-bcaa-06097a0d679f,technique,Dataset provenance can protect against poisoning of training data,relationship--eeb0c2dd-a563-492b-92ec-2ff10e303d4f,01 October 2024,01 October 2024
AML.M0017,Model Distribution Methods,course-of-action--432c3a44-3974-4b73-9eb9-fa5dd5298e47,mitigation,mitigates,AML.T0044,Full ML Model Access,attack-pattern--3de90963-bc9f-4ae1-b780-7d05e46eacdd,technique,"Not distributing the model in software to edge devices, can limit an adversary's ability to gain full access to the model.
",relationship--95f0e6ee-d274-4437-8edf-0d6b9f051eaf,12 April 2023,12 January 2024
AML.M0017,Model Distribution Methods,course-of-action--432c3a44-3974-4b73-9eb9-fa5dd5298e47,mitigation,mitigates,AML.T0010.003,Model,attack-pattern--452b8fdf-8679-4013-bb38-4d16f65430bc,technique,"An adversary could repackage the application with a malicious version of the model.
",relationship--f0224ef6-ac3f-426e-9d06-688675926474,12 April 2023,12 January 2024
AML.M0017,Model Distribution Methods,course-of-action--432c3a44-3974-4b73-9eb9-fa5dd5298e47,mitigation,mitigates,AML.T0043.000,White-Box Optimization,attack-pattern--ab01ba21-1438-4cd9-a588-92eb271086bc,technique,"With full access to the model, an adversary could perform white-box attacks.
",relationship--c18aaae0-8f5f-4ed2-afde-fa402b7c9058,12 April 2023,12 January 2024
AML.M0003,Model Hardening,course-of-action--216f862c-7f34-4676-a913-c4ec6cc4c2cd,mitigation,mitigates,AML.T0031,Erode ML Model Integrity,attack-pattern--8735735d-c09d-4298-8e64-9a2b6168a74c,technique,"Hardened models are less susceptible to integrity attacks.
",relationship--e78e2603-8851-4cb1-afa9-26757d56f190,12 April 2023,12 October 2023
AML.M0003,Model Hardening,course-of-action--216f862c-7f34-4676-a913-c4ec6cc4c2cd,mitigation,mitigates,AML.T0015,Evade ML Model,attack-pattern--071df654-813a-4708-85dc-f715f785d37f,technique,"Hardened models are more difficult to evade.
",relationship--35d555be-2b23-45fb-a52b-295ccce6c07d,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0043.001,Black-Box Optimization,attack-pattern--c4e52005-7416-45c4-9feb-8cd5fd34f70a,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--d1c35359-fab8-419c-916e-2dc2d887df06,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0014,Discover ML Model Family,attack-pattern--c552f0b5-2e2c-4f8f-badc-0876ecca7255,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--22e31c31-c4c8-42b3-8fd8-86b984d5dd4a,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0013,Discover ML Model Ontology,attack-pattern--943303ef-846b-49d6-b53f-b0b9341ac1ca,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--68b0f4e1-03d8-49ea-b1c5-8cdb58105d18,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0024.002,Extract ML Model,attack-pattern--f78e0ac3-6d72-42ed-b20a-e10d8c752cf6,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--9a09a00c-e920-4aff-827c-316dabdd8085,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0024.000,Infer Training Data Membership,attack-pattern--86b5f486-afb8-4aa9-991f-0e24d5737f0c,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--247dae90-cbb7-4514-a371-24cee2982dcd,12 April 2023,12 October 2023
AML.M0002,Passive ML Output Obfuscation,course-of-action--9f92e876-e2c0-4def-afee-626a4a79c524,mitigation,mitigates,AML.T0024.001,Invert ML Model,attack-pattern--e19c6f8a-f1e2-46cc-9387-03a3092f01ed,technique,"Suggested approaches:
  - Restrict the number of results shown
  - Limit specificity of output class ontology
  - Use randomized smoothing techniques
  - Reduce the precision of numerical outputs
",relationship--2cac8184-822b-4ae0-b0a5-9b23f1fa7c6e,12 April 2023,12 October 2023
AML.M0011,Restrict Library Loading,course-of-action--179e00cb-0948-4282-9132-f8a1f0ff6bd7,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,"Restrict library loading by ML artifacts.
",relationship--ab438913-b3c0-4672-9cbc-3e2e59bf3608,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0043.001,Black-Box Optimization,attack-pattern--c4e52005-7416-45c4-9feb-8cd5fd34f70a,technique,"Limit the number of queries users can perform in a given interval to shrink the attack surface for black-box attacks.
",relationship--6698cae1-2d23-45ab-9e07-e9c6bdfc78e9,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0034,Cost Harvesting,attack-pattern--ae71ca3a-8ca4-40d2-bdba-4276b29ac8f9,technique,"Limit the number of queries users can perform in a given interval to hinder an attacker's ability to send computationally expensive inputs
",relationship--5e4ea92d-e283-4234-860b-999203123162,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0029,Denial of ML Service,attack-pattern--8f644f37-e2e6-468e-b720-f395b8c27fbc,technique,"Limit the number of queries users can perform in a given interval to prevent a denial of service.
",relationship--bf9c8885-92cd-4ab8-a549-646ee1694c61,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0014,Discover ML Model Family,attack-pattern--c552f0b5-2e2c-4f8f-badc-0876ecca7255,technique,"Limit the amount of information an attacker can learn about a model's ontology through API queries.
",relationship--e20ae5d0-8412-4e6e-9958-75b5b3623b5d,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0013,Discover ML Model Ontology,attack-pattern--943303ef-846b-49d6-b53f-b0b9341ac1ca,technique,"Limit the amount of information an attacker can learn about a model's ontology through API queries.
",relationship--89213c4a-bccd-4461-8898-b4b7b2a3b899,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0024,Exfiltration via ML Inference API,attack-pattern--b07d147f-51c8-4eb6-9a05-09c86762a9c1,technique,"Limit the volume of API queries in a given period of time to regulate the amount and fidelity of potentially sensitive information an attacker can learn.
",relationship--f08cf33c-ac94-4000-b1c8-390fb912bfab,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0024.002,Extract ML Model,attack-pattern--f78e0ac3-6d72-42ed-b20a-e10d8c752cf6,technique,"Limit the volume of API queries in a given period of time to regulate the amount and fidelity of potentially sensitive information an attacker can learn.
",relationship--add8aacd-1581-44dd-80c7-380c9b0dac06,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0024.000,Infer Training Data Membership,attack-pattern--86b5f486-afb8-4aa9-991f-0e24d5737f0c,technique,"Limit the volume of API queries in a given period of time to regulate the amount and fidelity of potentially sensitive information an attacker can learn.
",relationship--d6992ef8-e0b8-4a20-a663-a59d1794c1cf,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0024.001,Invert ML Model,attack-pattern--e19c6f8a-f1e2-46cc-9387-03a3092f01ed,technique,"Limit the volume of API queries in a given period of time to regulate the amount and fidelity of potentially sensitive information an attacker can learn.
",relationship--46856582-fec6-4063-9a05-e769d0f5e6e3,12 April 2023,12 October 2023
AML.M0004,Restrict Number of ML Model Queries,course-of-action--46b3e92d-600b-47c9-80f5-ed62a5db0377,mitigation,mitigates,AML.T0046,Spamming ML System with Chaff Data,attack-pattern--6c1fca80-3ba9-41c9-8f7b-9824310a94f1,technique,"Limit the number of queries users can perform in a given interval to protect the system from chaff data spam.
",relationship--c8e7f861-0992-4589-a1c0-c70a603c957b,12 April 2023,12 October 2023
AML.M0007,Sanitize Training Data,course-of-action--9395d240-cc32-452a-911b-04feea01bcfb,mitigation,mitigates,AML.T0010.002,Data,attack-pattern--8d644240-ad99-4410-a7f8-3ef8f53a463e,technique,"Detect and remove or remediate poisoned data to avoid adversarial model drift or backdoor attacks.
",relationship--c444e7de-83cc-4a6e-99bd-8509f923cb3d,12 April 2023,12 October 2023
AML.M0007,Sanitize Training Data,course-of-action--9395d240-cc32-452a-911b-04feea01bcfb,mitigation,mitigates,AML.T0018.000,Poison ML Model,attack-pattern--e0eb2b64-aebd-4412-80f3-b71d7805a65f,technique,"Prevent attackers from leveraging poisoned datasets to launch backdoor attacks against a model.
",relationship--29b6aa3b-fecb-4d1c-bdb2-58f90788123e,12 April 2023,12 October 2023
AML.M0007,Sanitize Training Data,course-of-action--9395d240-cc32-452a-911b-04feea01bcfb,mitigation,mitigates,AML.T0020,Poison Training Data,attack-pattern--0ec538ca-589b-4e42-bcaa-06097a0d679f,technique,"Detect modification of data and labels which may cause adversarial model drift or backdoor attacks.
",relationship--0f06ec3d-4343-4363-96a0-fa9492dc8edf,12 April 2023,12 October 2023
AML.M0006,Use Ensemble Methods,course-of-action--dcb586a2-1135-4e2a-97bd-d4adbc79758b,mitigation,mitigates,AML.T0014,Discover ML Model Family,attack-pattern--c552f0b5-2e2c-4f8f-badc-0876ecca7255,technique,"Use multiple different models to fool adversaries of which type of model is used and how the model used.
",relationship--3a3cab15-6b39-4d41-8e03-23a15a5cba42,12 April 2023,12 October 2023
AML.M0006,Use Ensemble Methods,course-of-action--dcb586a2-1135-4e2a-97bd-d4adbc79758b,mitigation,mitigates,AML.T0031,Erode ML Model Integrity,attack-pattern--8735735d-c09d-4298-8e64-9a2b6168a74c,technique,"Using multiple different models increases robustness to attack.
",relationship--bc86c7f4-d989-4a2c-9ff8-fb21038e0287,12 April 2023,12 October 2023
AML.M0006,Use Ensemble Methods,course-of-action--dcb586a2-1135-4e2a-97bd-d4adbc79758b,mitigation,mitigates,AML.T0015,Evade ML Model,attack-pattern--071df654-813a-4708-85dc-f715f785d37f,technique,"Using multiple different models increases robustness to attack.
",relationship--f739f509-651f-4fac-9342-a4b189d4a82f,12 April 2023,12 October 2023
AML.M0006,Use Ensemble Methods,course-of-action--dcb586a2-1135-4e2a-97bd-d4adbc79758b,mitigation,mitigates,AML.T0010.001,ML Software,attack-pattern--d8292a1c-21e7-4b45-b110-0e05feb30a9a,technique,"Using multiple different models ensures minimal performance loss if security flaw is found in tool for one model or family.
",relationship--c8bf0bed-9028-48a4-97d8-57d5e9387dd5,12 April 2023,12 October 2023
AML.M0006,Use Ensemble Methods,course-of-action--dcb586a2-1135-4e2a-97bd-d4adbc79758b,mitigation,mitigates,AML.T0010.003,Model,attack-pattern--452b8fdf-8679-4013-bb38-4d16f65430bc,technique,"Using multiple different models ensures minimal performance loss if security flaw is found in tool for one model or family.
",relationship--f3f9ba2a-b6d3-4171-b776-4c0fd425d1dd,12 April 2023,12 October 2023
AML.M0009,Use Multi-Modal Sensors,course-of-action--1bb9d9a7-c05a-470f-a709-64bd240e2eb0,mitigation,mitigates,AML.T0015,Evade ML Model,attack-pattern--071df654-813a-4708-85dc-f715f785d37f,technique,"Using a variety of sensors can make it more difficult for an attacker to compromise and produce malicious results.
",relationship--e5396756-390d-43b9-b3d3-c998869b9498,12 April 2023,12 October 2023
AML.M0009,Use Multi-Modal Sensors,course-of-action--1bb9d9a7-c05a-470f-a709-64bd240e2eb0,mitigation,mitigates,AML.T0041,Physical Environment Access,attack-pattern--4d5c6974-0307-4535-bf37-7bb4c6a2ef47,technique,"Using a variety of sensors can make it more difficult for an attacker with physical access to compromise and produce malicious results.
",relationship--10720f12-fe1a-4b30-93a8-2f69f33729b7,12 April 2023,12 October 2023
AML.M0018,User Training,course-of-action--cce983e7-13a2-4545-8c39-ec6c8dff148d,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,"Train users to identify attempts of manipulation to prevent them from running unsafe code which when executed could develop unsafe artifacts. These artifacts may have a detrimental effect on the system.
",relationship--5e634baa-bdb1-4ea3-bdc7-4fbfa88f1fac,12 April 2023,12 October 2023
AML.M0018,User Training,course-of-action--cce983e7-13a2-4545-8c39-ec6c8dff148d,mitigation,mitigates,AML.T0011,User Execution,attack-pattern--8c849dd4-5d15-45aa-b5b2-59c96a3ab939,technique,"Training users to be able to identify attempts at manipulation will make them less susceptible to performing techniques that cause the execution of malicious code.
",relationship--40424d8a-5de5-4658-87a0-85568fde2e4e,12 April 2023,12 October 2023
AML.M0008,Validate ML Model,course-of-action--01c2ec0a-e257-4a75-9e59-f71aa6362b6e,mitigation,mitigates,AML.T0018.001,Inject Payload,attack-pattern--a50f02df-1130-4945-94bb-7857952da585,technique,"Ensure that acquired models do not respond to potential backdoor triggers or adversarial bias.
",relationship--041e524f-ce40-44fb-be10-9ba2292ee7b2,12 April 2023,12 January 2024
AML.M0008,Validate ML Model,course-of-action--01c2ec0a-e257-4a75-9e59-f71aa6362b6e,mitigation,mitigates,AML.T0010.003,Model,attack-pattern--452b8fdf-8679-4013-bb38-4d16f65430bc,technique,"Ensure that acquired models do not respond to potential backdoor triggers or adversarial bias.
",relationship--28a7467d-ed66-4b74-b5cc-5e7b14d26f1c,12 April 2023,12 January 2024
AML.M0008,Validate ML Model,course-of-action--01c2ec0a-e257-4a75-9e59-f71aa6362b6e,mitigation,mitigates,AML.T0018.000,Poison ML Model,attack-pattern--e0eb2b64-aebd-4412-80f3-b71d7805a65f,technique,"Ensure that trained models do not respond to potential backdoor triggers or adversarial bias.
",relationship--7cefef5d-aa19-4170-b415-e9ca2db8e062,12 April 2023,12 January 2024
AML.M0014,Verify ML Artifacts,course-of-action--cdccb3ab-2dde-41a9-a988-783a25b7bd00,mitigation,mitigates,AML.T0010,ML Supply Chain Compromise,attack-pattern--d2cf31e0-a550-4fe0-8fdb-8941b3ac00d9,technique,"Introduce proper checking of signatures to ensure that unsafe ML artifacts will not be introduced to the system.
",relationship--6299066e-0ff9-4d89-bb8f-cb1b0f04b9b3,12 April 2023,12 October 2023
AML.M0014,Verify ML Artifacts,course-of-action--cdccb3ab-2dde-41a9-a988-783a25b7bd00,mitigation,mitigates,AML.T0019,Publish Poisoned Datasets,attack-pattern--f4fc2abd-71a4-401a-a742-18fc5aeb4bc3,technique,"Determine validity of published data in order to avoid using poisoned data that introduces vulnerabilities.
",relationship--ba2f59be-65ed-4f71-8b25-c40c0316b4cc,12 April 2023,12 October 2023
AML.M0014,Verify ML Artifacts,course-of-action--cdccb3ab-2dde-41a9-a988-783a25b7bd00,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,"Introduce proper checking of signatures to ensure that unsafe ML artifacts will not be executed in the system.
",relationship--29f0ff78-37c3-4eee-b43d-d7b6ad221922,12 April 2023,12 October 2023
AML.M0016,Vulnerability Scanning,course-of-action--79752061-aac1-4ed9-b7f3-3b4dc5e81280,mitigation,mitigates,AML.T0018,Backdoor ML Model,attack-pattern--c704a49c-abf0-4258-9919-a862b1865469,technique,"Techniques such as neural payload injection can make model artifacts vulnerable to adversarial queries. Scan model artifacts for signs of compromise.
",relationship--71ad3705-8153-4733-b9e8-771bf4963b6e,12 April 2023,12 January 2024
AML.M0016,Vulnerability Scanning,course-of-action--79752061-aac1-4ed9-b7f3-3b4dc5e81280,mitigation,mitigates,AML.T0011.000,Unsafe ML Artifacts,attack-pattern--be6ef5c5-1ecb-486d-9743-42085bd2c256,technique,"Scan ML artifacts for vulnerabilities before execution.
",relationship--8355c7ce-abbe-44b9-bd2e-b83f91160b1f,12 April 2023,12 January 2024